{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0daf1ac5-2eda-4a81-9cb8-3013ee3c2bc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 安装必要依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36aba50b-020a-4edc-b5e0-bf4c63274d16",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-12-20T09:19:52.489607Z",
     "iopub.status.busy": "2024-12-20T09:19:52.489466Z",
     "iopub.status.idle": "2024-12-20T09:20:40.511522Z",
     "shell.execute_reply": "2024-12-20T09:20:40.510900Z",
     "shell.execute_reply.started": "2024-12-20T09:19:52.489587Z"
    },
    "scrolled": true,
    "tags": []
   },
  
   "source": [
    "%pip install sqlalchemy\n",
    "%pip install llama-index-core \n",
    "%pip install llama-index-llms-openai-like \n",
    "%pip install llama-index-readers-file \n",
    "%pip install llama-index-vector-stores-milvus\n",
    "%pip install llamaindex-py-client\n",
    "%pip install openai\n",
    "%pip install supabase\n",
    "%pip install llama-index-embeddings-instructor\n",
    "%pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77600ac7-75f9-4379-ae58-4e716c89cf37",
   "metadata": {},
   "source": [
    "# 设置环境变量和加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890f5ad8-7da4-460c-a4fe-a200248574d8",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-12-20T09:42:41.871849Z",
     "iopub.status.busy": "2024-12-20T09:42:41.871500Z",
     "iopub.status.idle": "2024-12-20T09:42:41.874698Z",
     "shell.execute_reply": "2024-12-20T09:42:41.874122Z",
     "shell.execute_reply.started": "2024-12-20T09:42:41.871827Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入os模块\n",
    "import os\n",
    "\n",
    "# 设置环境变量\n",
    "os.environ['ZHIPU_API_KEY'] = '你的APIKEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8a66b11-b12a-413e-be64-fcd15ae92ef1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:42:43.233860Z",
     "iopub.status.busy": "2024-12-20T09:42:43.233519Z",
     "iopub.status.idle": "2024-12-20T09:42:47.402816Z",
     "shell.execute_reply": "2024-12-20T09:42:47.402104Z",
     "shell.execute_reply.started": "2024-12-20T09:42:43.233840Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.llms.openai_like import OpenAILike\n",
    "\n",
    "LLM = OpenAILike(\n",
    "    model = \"glm-4-flash\",\n",
    "    api_base=\"https://open.bigmodel.cn/api/paas/v4/\",\n",
    "    api_key = os.getenv(\"ZHIPU_API_KEY\"),\n",
    "    is_chat_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5781d837-ae3a-4665-bffa-655c7457d52c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:42:49.048965Z",
     "iopub.status.busy": "2024-12-20T09:42:49.048316Z",
     "iopub.status.idle": "2024-12-20T09:42:49.104042Z",
     "shell.execute_reply": "2024-12-20T09:42:49.103342Z",
     "shell.execute_reply.started": "2024-12-20T09:42:49.048933Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入必要的库和模块\n",
    "from openai import OpenAI \n",
    "from typing import Any, List  # 导入类型注解，用于函数参数和返回值的类型提示\n",
    "from llama_index.core.embeddings import BaseEmbedding  # 导入基类，用于继承创建嵌入模型\n",
    "from pydantic import Field  # 导入Field，用于Pydantic模型中定义字段的元数据\n",
    "\n",
    "# 定义ZhipuEmbeddings类，继承自BaseEmbedding基类\n",
    "class ZhipuEmbeddings(BaseEmbedding):\n",
    "    # 类属性client，使用Field定义，并且通过lambda函数设置默认值\n",
    "    # 默认值是一个ZhipuAI实例，使用环境变量ZHIPU_API_KEY作为API密钥\n",
    "    client: OpenAI = Field(default_factory=lambda: OpenAI(api_key=os.environ['ZHIPU_API_KEY'], base_url=\"https://open.bigmodel.cn/api/paas/v4/\"))\n",
    "\n",
    "    # 类的构造函数，初始化模型名称和其他参数\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"embedding-2\",  # 默认使用\"embedding-2\"模型\n",
    "        **kwargs: Any,  # 其他关键字参数\n",
    "    ) -> None:\n",
    "        super().__init__(model_name=model_name, **kwargs)  # 调用基类的构造函数\n",
    "        self._model = model_name  # 保存模型名称\n",
    "\n",
    "    # 调用Zhipu AI服务进行嵌入的方法\n",
    "    def invoke_embedding(self, query: str) -> List[float]:\n",
    "        # 使用client调用Zhipu AI服务的嵌入接口\n",
    "        response = self.client.embeddings.create(model=self._model, input=[query])\n",
    "        # 检查响应是否成功\n",
    "        if response.data and len(response.data) > 0:\n",
    "            return response.data[0].embedding  # 返回嵌入结果\n",
    "        else:\n",
    "            raise ValueError(\"Failed to get embedding from ZhipuAI API\")  # 如果失败，抛出异常\n",
    "\n",
    "    # 获取查询嵌入的方法，调用invoke_embedding\n",
    "    def _get_query_embedding(self, query: str) -> List[float]:\n",
    "        return self.invoke_embedding(query)\n",
    "\n",
    "    # 获取文本嵌入的方法，调用invoke_embedding\n",
    "    def _get_text_embedding(self, text: str) -> List[float]:\n",
    "        return self.invoke_embedding(text)\n",
    "\n",
    "    # 获取多个文本嵌入的方法，对每个文本调用_get_text_embedding\n",
    "    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        return [self._get_text_embedding(text) for text in texts]\n",
    "\n",
    "    # 异步获取查询嵌入的方法，调用_get_query_embedding\n",
    "    async def _aget_query_embedding(self, query: str) -> List[float]:\n",
    "        return self._get_query_embedding(query)\n",
    "\n",
    "    # 异步获取文本嵌入的方法，调用_get_text_embedding\n",
    "    async def _aget_text_embedding(self, text: str) -> List[float]:\n",
    "        return self._get_text_embedding(text)\n",
    "\n",
    "    # 异步获取多个文本嵌入的方法，调用_get_text_embeddings\n",
    "    async def _aget_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        return self._get_text_embeddings(texts)\n",
    "embedding = ZhipuEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902e6e3d-8618-45fe-80d0-113756de9da7",
   "metadata": {},
   "source": [
    "# 配置SQL_llamaindex连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb60592-3a87-4dc5-8d3c-fc7927a1d864",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-12-20T09:42:52.405520Z",
     "iopub.status.busy": "2024-12-20T09:42:52.405042Z",
     "iopub.status.idle": "2024-12-20T09:42:56.029397Z",
     "shell.execute_reply": "2024-12-20T09:42:56.028752Z",
     "shell.execute_reply.started": "2024-12-20T09:42:52.405486Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入所需的库\n",
    "from sqlalchemy import create_engine  # SQLAlchemy库，用于创建数据库连接引擎\n",
    "from llama_index.core import SQLDatabase  # 用于创建和管理SQL数据库的llama-index库的核心组件\n",
    "from llama_index.core import Settings  # 用于配置llama-index的设置\n",
    "\n",
    "# https://data.sh.gov.cn/view/detail/index.html?type=cp&&id=AA5002015022 数据下载\n",
    "# https://supabase.com/ SQL数据库\n",
    "# 创建一个连接到SQL数据库的引擎\n",
    "engine = create_engine('postgresql://postgres.fpowouuctpaicslyrwjb:你的SQL数据库@aws-0-ap-southeast-1.pooler.supabase.com:6543/postgres')\n",
    "\n",
    "# 使用创建的引擎初始化SQLDatabase对象，并指定数据库架构和要包含的表\n",
    "# 这里的\"schema\"参数指定了数据库的架构，\"include_tables\"参数指定了要包含的表名\n",
    "sql_database = SQLDatabase(engine, schema=\"public\", include_tables=[\"company\"])\n",
    "\n",
    "Settings.llm = LLM # 需要配置\n",
    "\n",
    "Settings.embed_model = embedding # 需要配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4690e47d-a13b-46e0-95e7-b78b5c4f0ee2",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-12-20T09:42:59.998371Z",
     "iopub.status.busy": "2024-12-20T09:42:59.997839Z",
     "iopub.status.idle": "2024-12-20T09:43:00.001870Z",
     "shell.execute_reply": "2024-12-20T09:43:00.001338Z",
     "shell.execute_reply.started": "2024-12-20T09:42:59.998341Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.prompts.base import PromptTemplate\n",
    "from llama_index.core.prompts.prompt_type import PromptType\n",
    "\n",
    "MODIFIED_TEXT_TO_SQL_TMPL = (\n",
    "    \"输入详细信息: SELECT 企业名称 FROM company Where 证书编号 = {query_str}\\n\"\n",
    "    \"SQLQuery: \"\n",
    ")\n",
    "\n",
    "# 使用 PromptTemplate 类创建一个提示模板对象 MODIFIED_TEXT_TO_SQL_PROMPT，\n",
    "# 传入前面定义的模板字符串 MODIFIED_TEXT_TO_SQL_TMPL 和提示类型 PromptType.TEXT_TO_SQL\n",
    "MODIFIED_TEXT_TO_SQL_PROMPT = PromptTemplate(\n",
    "    MODIFIED_TEXT_TO_SQL_TMPL,\n",
    "    prompt_type=PromptType.TEXT_TO_SQL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49ab62f1-28be-46f1-9604-d93bf59b9deb",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-12-20T09:43:01.977251Z",
     "iopub.status.busy": "2024-12-20T09:43:01.976923Z",
     "iopub.status.idle": "2024-12-20T09:43:01.980903Z",
     "shell.execute_reply": "2024-12-20T09:43:01.980318Z",
     "shell.execute_reply.started": "2024-12-20T09:43:01.977231Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "\n",
    "query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database, \n",
    "    tables=[\"company\"],\n",
    "    llm=Settings.llm,\n",
    "    response_mode=\"context\"\n",
    ")\n",
    "query_engine.update_prompts(\n",
    "    {\"sql_retriever:text_to_sql_prompt\": MODIFIED_TEXT_TO_SQL_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe03982-7ff9-4d43-89c2-6bacbd9a09a4",
   "metadata": {},
   "source": [
    "# 配置llamaindex_RAG 连接（使用标识切块）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b98bd1d-1521-468c-9c55-5a90fd2a1a96",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-12-20T09:44:10.303274Z",
     "iopub.status.busy": "2024-12-20T09:44:10.302917Z",
     "iopub.status.idle": "2024-12-20T09:44:10.323716Z",
     "shell.execute_reply": "2024-12-20T09:44:10.323160Z",
     "shell.execute_reply.started": "2024-12-20T09:44:10.303254Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 从指定文件读取，输入为List\n",
    "from llama_index.core import SimpleDirectoryReader,Document\n",
    "documents = SimpleDirectoryReader(input_files=['/mnt/workspace/llamaindex_SQL_RAG-/高企.txt']).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df7b9e1-c176-468a-adaa-b2a7e301994a",
   "metadata": {},
   "source": [
    "## 创建索引并加载（第一次执行）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "497fd3b3-5a44-494c-b20f-7e5b6cbe338c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-12-20T09:40:01.079912Z",
     "iopub.status.busy": "2024-12-20T09:40:01.079442Z",
     "iopub.status.idle": "2024-12-20T09:40:03.241786Z",
     "shell.execute_reply": "2024-12-20T09:40:03.241211Z",
     "shell.execute_reply.started": "2024-12-20T09:40:01.079891Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import TextSplitter\n",
    "from llama_index.core.ingestion.pipeline import run_transformations\n",
    "from typing import List\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "\n",
    "class CodeBlockSplitter(TextSplitter):\n",
    "    def split_text(self, text: str) -> List[str]:\n",
    "        return text.split(\"```\")\n",
    "    def __init__(self, **kwargs):\n",
    "          super().__init__(**kwargs)\n",
    "\n",
    "\n",
    "transformations = [CodeBlockSplitter(chunk_size=0, chunk_overlap=0)]\n",
    "\n",
    "# 导入用于执行转换操作的函数\n",
    "from llama_index.core.ingestion.pipeline import run_transformations\n",
    "# 执行转换操作，将文档转换为节点\n",
    "# documents是待处理的文档列表\n",
    "# transformations是我们定义的转换操作列表\n",
    "nodes = run_transformations(documents, transformations=transformations)\n",
    "\n",
    "# 设置向量维度，这里是1024维\n",
    "dimensions = 1024\n",
    "vector_store = MilvusVectorStore(uri=\"/mnt/workspace/llamaindex_SQL_RAG-/index/milvus_demo.db\", dim=1024, overwrite=True)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(documents, storage_context=storage_context, embed_model=embedding)\n",
    "\n",
    "\n",
    "# 创建向量存储索引，将节点、存储上下文和嵌入模型作为参数\n",
    "# nodes是我们之前创建的节点列表\n",
    "# storage_context是我们创建的存储上下文\n",
    "# embed_model是用于生成节点嵌入的模型，这里需要提前定义\n",
    "index = VectorStoreIndex(\n",
    "    nodes=nodes,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=embedding,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248fab89-5617-453e-866b-b80abe381685",
   "metadata": {},
   "source": [
    "## 保存索引并加载（之后执行）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "740cc94d-bdf4-4e29-9173-196f29cc1586",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-12-20T09:44:13.699091Z",
     "iopub.status.busy": "2024-12-20T09:44:13.698746Z",
     "iopub.status.idle": "2024-12-20T09:44:14.128947Z",
     "shell.execute_reply": "2024-12-20T09:44:14.128408Z",
     "shell.execute_reply.started": "2024-12-20T09:44:13.699057Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "\n",
    "# 定义一个字符串变量persist_dir，用于指定存储索引的目录路径\n",
    "persist_dir = \"/mnt/workspace/llamaindex_SQL_RAG-/index/milvus_demo.db\"\n",
    "\n",
    "vector_store = MilvusVectorStore(uri=persist_dir, dim=1024, overwrite=False)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(documents, storage_context=storage_context, embed_model=embedding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b4e46b-1982-4daf-a2ad-0c22b7305f88",
   "metadata": {},
   "source": [
    "# 测试结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fff618b-8ed1-4484-bd13-6b2aec375a40",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-12-20T09:44:16.157948Z",
     "iopub.status.busy": "2024-12-20T09:44:16.157620Z",
     "iopub.status.idle": "2024-12-20T09:44:23.373837Z",
     "shell.execute_reply": "2024-12-20T09:44:23.373330Z",
     "shell.execute_reply.started": "2024-12-20T09:44:16.157928Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "上海蜂果网络科技有限公司成立于2014年，是一家专注于网络游戏研发和运营的公司。该公司由一群热爱游戏的80后创办，并得到了国内上市公司的投资。员工主要来自完美、腾讯、Intel、高通等国内外知名的互联网/IT企业，其中核心成员拥有至少5年以上的成功网游研发和运营经验。蜂果团队致力于手机游戏研发，以扎实的技术基础、热情的创业精神以及对移动玩家的深刻理解为基础，秉持“用心做好游戏”的原则，并将其作为团队的目标。\n"
     ]
    }
   ],
   "source": [
    "# 假设query_engine和index是已经定义好的对象，且Settings.llm也是可用的\n",
    "query_str = \"GR202131000001\"\n",
    "# 使用第一个查询引擎进行查询\n",
    "response = query_engine.query(query_str)\n",
    "# 初始化第二个查询引擎\n",
    "query_engine2 = index.as_query_engine(llm=Settings.llm)\n",
    "\n",
    "# 使用第二个查询引擎进行查询，并将第一个查询的结果作为查询内容\n",
    "response2 = query_engine2.query(f\"请给出{response}的详细介绍\")\n",
    "print(response2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "844e8827-fafa-4838-b2cf-cf704b179dc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:44:28.297058Z",
     "iopub.status.busy": "2024-12-20T09:44:28.296575Z",
     "iopub.status.idle": "2024-12-20T09:44:33.796699Z",
     "shell.execute_reply": "2024-12-20T09:44:33.796146Z",
     "shell.execute_reply.started": "2024-12-20T09:44:28.297024Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GR202131000001 这个编号看起来像是一个特定的代码或标识符，可能是用于某个项目、订单、合同、文件或其他实体。由于没有具体的上下文信息，很难确定这个编号的确切含义。\n",
      "\n",
      "以下是一些可能的解释：\n",
      "\n",
      "1. **项目编号**：可能是某个项目或工程的编号，用于跟踪和管理。\n",
      "2. **订单编号**：可能是某个订单的编号，用于跟踪订单状态和物流信息。\n",
      "3. **合同编号**：可能是某个合同或协议的编号，用于法律和财务记录。\n",
      "4. **文件编号**：可能是某个文件或报告的编号，用于归档和检索。\n",
      "5. **产品编号**：可能是某个产品或服务的编号，用于库存管理和销售。\n",
      "\n",
      "如果您能提供更多关于这个编号的信息或上下文，我可以尝试给出更准确的解释。\n"
     ]
    }
   ],
   "source": [
    "response = LLM.complete(\"GR202131000001\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f58bbf-b278-4497-bb3f-b4ff8b13b3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
